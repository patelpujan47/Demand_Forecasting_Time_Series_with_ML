{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13aff848",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7ea8c9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\patel\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.stattools import acf, pacf, adfuller\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Input, Bidirectional, LSTM, Conv1D, MaxPooling1D, Flatten, Concatenate, Dense, GRU\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7353c81f",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07043321",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "date",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "store",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "item",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "sales",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "754ab5fa-9eda-4e39-aac0-4463e2e6fa35",
       "rows": [
        [
         "829786",
         "2015-02-22",
         "5",
         "46",
         "41"
        ],
        [
         "726954",
         "2013-07-26",
         "9",
         "40",
         "35"
        ],
        [
         "798697",
         "2015-01-06",
         "8",
         "44",
         "17"
        ],
        [
         "105315",
         "2016-05-18",
         "8",
         "6",
         "86"
        ],
        [
         "600976",
         "2013-08-11",
         "10",
         "33",
         "93"
        ],
        [
         "460961",
         "2015-03-21",
         "3",
         "26",
         "63"
        ],
        [
         "672866",
         "2015-06-18",
         "9",
         "37",
         "32"
        ],
        [
         "73803",
         "2015-02-03",
         "1",
         "5",
         "9"
        ],
        [
         "18787",
         "2014-06-12",
         "1",
         "2",
         "69"
        ],
        [
         "859347",
         "2016-02-02",
         "1",
         "48",
         "30"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>store</th>\n",
       "      <th>item</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>829786</th>\n",
       "      <td>2015-02-22</td>\n",
       "      <td>5</td>\n",
       "      <td>46</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>726954</th>\n",
       "      <td>2013-07-26</td>\n",
       "      <td>9</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798697</th>\n",
       "      <td>2015-01-06</td>\n",
       "      <td>8</td>\n",
       "      <td>44</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105315</th>\n",
       "      <td>2016-05-18</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600976</th>\n",
       "      <td>2013-08-11</td>\n",
       "      <td>10</td>\n",
       "      <td>33</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460961</th>\n",
       "      <td>2015-03-21</td>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>672866</th>\n",
       "      <td>2015-06-18</td>\n",
       "      <td>9</td>\n",
       "      <td>37</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73803</th>\n",
       "      <td>2015-02-03</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18787</th>\n",
       "      <td>2014-06-12</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>859347</th>\n",
       "      <td>2016-02-02</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              date  store  item  sales\n",
       "829786  2015-02-22      5    46     41\n",
       "726954  2013-07-26      9    40     35\n",
       "798697  2015-01-06      8    44     17\n",
       "105315  2016-05-18      8     6     86\n",
       "600976  2013-08-11     10    33     93\n",
       "460961  2015-03-21      3    26     63\n",
       "672866  2015-06-18      9    37     32\n",
       "73803   2015-02-03      1     5      9\n",
       "18787   2014-06-12      1     2     69\n",
       "859347  2016-02-02      1    48     30"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('data/train.csv')\n",
    "\n",
    "df_train.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c83f8b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "date",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "store",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "item",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "c1492056-08fc-4e61-bc5e-e34ecb7f9460",
       "rows": [
        [
         "0",
         "2018-01-01",
         "1",
         "1"
        ],
        [
         "1",
         "2018-01-02",
         "1",
         "1"
        ],
        [
         "2",
         "2018-01-03",
         "1",
         "1"
        ],
        [
         "3",
         "2018-01-04",
         "1",
         "1"
        ],
        [
         "4",
         "2018-01-05",
         "1",
         "1"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>store</th>\n",
       "      <th>item</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-05</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  store  item\n",
       "0  2018-01-01      1     1\n",
       "1  2018-01-02      1     1\n",
       "2  2018-01-03      1     1\n",
       "3  2018-01-04      1     1\n",
       "4  2018-01-05      1     1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv('data/test.csv')\n",
    "\n",
    "df_test = df_test.drop(columns=['id'], axis=1)\n",
    "\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0975f857",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43966e05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date   store  item   sales\n",
       "False  False  False  False    913000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Null values\n",
    "df_train.isnull().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b721ad7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date     0\n",
       "store    0\n",
       "item     0\n",
       "sales    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NA values\n",
    "df_train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3dcb2bd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Duplicates\n",
    "df_train.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "136b4bee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date     object\n",
       "store     int64\n",
       "item      int64\n",
       "sales     int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99f5652",
   "metadata": {},
   "source": [
    "Since date column is object - convert it to date format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4165d3cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "date",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "store",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "item",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "sales",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "0af9f9c1-d931-4d1b-9530-e9de9ee37510",
       "rows": [
        [
         "0",
         "2013-01-01 00:00:00",
         "1",
         "1",
         "13"
        ],
        [
         "1",
         "2013-01-02 00:00:00",
         "1",
         "1",
         "11"
        ],
        [
         "2",
         "2013-01-03 00:00:00",
         "1",
         "1",
         "14"
        ],
        [
         "3",
         "2013-01-04 00:00:00",
         "1",
         "1",
         "13"
        ],
        [
         "4",
         "2013-01-05 00:00:00",
         "1",
         "1",
         "10"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>store</th>\n",
       "      <th>item</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-01-03</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-01-05</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  store  item  sales\n",
       "0 2013-01-01      1     1     13\n",
       "1 2013-01-02      1     1     11\n",
       "2 2013-01-03      1     1     14\n",
       "3 2013-01-04      1     1     13\n",
       "4 2013-01-05      1     1     10"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['date'] = pd.to_datetime(df_train['date'], format=\"%Y-%m-%d\")\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61d24c87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date     datetime64[ns]\n",
       "store             int64\n",
       "item              int64\n",
       "sales             int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3321cf54",
   "metadata": {},
   "source": [
    "Make sure the data is sorted as per date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "561e3087",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "date",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "store",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "item",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "sales",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "a27316e0-eb44-4c8c-9dc1-9226ee1546ac",
       "rows": [
        [
         "0",
         "2013-01-01 00:00:00",
         "1",
         "1",
         "13"
        ],
        [
         "1",
         "2013-01-01 00:00:00",
         "1",
         "2",
         "33"
        ],
        [
         "2",
         "2013-01-01 00:00:00",
         "1",
         "3",
         "15"
        ],
        [
         "3",
         "2013-01-01 00:00:00",
         "1",
         "4",
         "10"
        ],
        [
         "4",
         "2013-01-01 00:00:00",
         "1",
         "5",
         "11"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>store</th>\n",
       "      <th>item</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  store  item  sales\n",
       "0 2013-01-01      1     1     13\n",
       "1 2013-01-01      1     2     33\n",
       "2 2013-01-01      1     3     15\n",
       "3 2013-01-01      1     4     10\n",
       "4 2013-01-01      1     5     11"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = df_train.sort_values(by=['date', 'store', 'item']).reset_index(drop=True)\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40657e80",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34874674",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=df_train, x='date', y='sales')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d8dead",
   "metadata": {},
   "source": [
    "Sales increases per year - positive trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62635385",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data=df_train, x='store', y='sales')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90921c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,8))\n",
    "sns.barplot(data=df_train, x='item', y='sales')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d037fc",
   "metadata": {},
   "source": [
    "Each store has different demand and each item has a different demand - so each store item pair will have a different demand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5425578",
   "metadata": {},
   "outputs": [],
   "source": [
    "pivoted_sales = df_train.pivot_table(index='date', columns=['store', 'item'], values='sales', aggfunc='sum')\n",
    "\n",
    "pivoted_sales.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3bbd45a",
   "metadata": {},
   "source": [
    "## ML Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b656fcb3",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382e364e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_rf = df_train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f1de7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_rf = X_rf['sales']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0674b10",
   "metadata": {},
   "source": [
    "Reshaping not required for RF. Convert date to ordinal as RF doesn't understand date type - Add date related features as date is not significant when it comes to regression models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ae4594",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_rf['dow'] = X_rf['date'].dt.dayofweek\n",
    "X_rf['month'] = X_rf['date'].dt.month\n",
    "X_rf['year'] = X_rf['date'].dt.year\n",
    "\n",
    "\n",
    "# Converting 'date' column to ordinal to use it as a feature\n",
    "X_rf['date'] = X_rf['date'].apply(lambda x: x.toordinal())\n",
    "\n",
    "X_rf.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1ef8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the 'sales' column from features\n",
    "X_rf = X_rf.drop(columns=['sales'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "babf5ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into training and testing sets\n",
    "X_train_rf, X_test_rf, y_train_rf, y_test_rf = train_test_split(X_rf, y_rf, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5145503",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model\n",
    "rf_model = RandomForestRegressor(n_estimators=100,\n",
    "                                 max_depth=10,\n",
    "                                 min_samples_split=2,\n",
    "                                 min_samples_leaf=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0884ea91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RF Modeling fitting\n",
    "rf_model.fit(X_train_rf,y_train_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b602b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicting on training set\n",
    "y_train_pred_rf = rf_model.predict(X_train_rf)\n",
    "\n",
    "# Calculating Mean Squared Error on training set\n",
    "mse_rf_train = mean_squared_error(y_train_rf, y_train_pred_rf)\n",
    "print(\"Mean Squared Error on Training Set:\", mse_rf_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a1e40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicting on testing set\n",
    "y_test_pred_rf = rf_model.predict(X_test_rf)\n",
    "\n",
    "# Calculating Mean Squared Error on testing set\n",
    "mse_rf_test = mean_squared_error(y_test_rf, y_test_pred_rf)\n",
    "print(\"Mean Squared Error on Testing Set:\", mse_rf_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eaf321b",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b2e1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_xgb = df_train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d46ee21",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_xgb = X_xgb['sales']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dab9a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_xgb['dow'] = X_xgb['date'].dt.dayofweek\n",
    "X_xgb['day'] = X_xgb['date'].dt.day\n",
    "X_xgb['month'] = X_xgb['date'].dt.month\n",
    "X_xgb['year'] = X_xgb['date'].dt.year\n",
    "\n",
    "X_xgb.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b585612a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_xgb = X_xgb.drop(columns=['sales', 'date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe63b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into training and testing sets\n",
    "X_train_xgb, X_test_xgb, y_train_xgb, y_test_xgb = train_test_split(X_xgb, y_xgb, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b834fd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_model = xgb.XGBRegressor(n_estimator=100,learning_rate=0.08, gamma=0, subsample=0.75, colsample_bytree=1, max_depth=7, booster='gbtree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f294f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_model.fit(X_train_xgb,y_train_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e0c6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicting on training set\n",
    "y_train_pred_xgb = xg_model.predict(X_train_xgb)\n",
    "\n",
    "# Calculating Mean Squared Error on training set\n",
    "mse_xgb_train = mean_squared_error(y_train_xgb, y_train_pred_xgb)\n",
    "print(\"Mean Squared Error on Training Set:\", mse_xgb_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9524b3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicting on testing set\n",
    "y_test_pred_xgb = xg_model.predict(X_test_xgb)\n",
    "\n",
    "# Calculating Mean Squared Error on testing set\n",
    "mse_xgb_test = mean_squared_error(y_test_xgb, y_test_pred_xgb)\n",
    "print(\"Mean Squared Error on Testing Set:\", mse_xgb_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b809f1f0",
   "metadata": {},
   "source": [
    "### ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea9fb4f",
   "metadata": {},
   "source": [
    "Need to extract date features, perform scaling and reshaping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60347a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ann = df_train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2ee3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract y\n",
    "y_ann = X_ann['sales']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107b216d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale and reshape y\n",
    "y_scaler_ann = MinMaxScaler()\n",
    "\n",
    "y_ann_scaled = y_scaler_ann.fit_transform(y_ann.values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7214bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ann['year'] = X_ann['date'].dt.year\n",
    "X_ann['month'] = X_ann['date'].dt.month\n",
    "X_ann['day_of_week'] = X_ann['date'].dt.dayofweek  # Monday=0, Sunday=6\n",
    "X_ann['day_of_year'] = X_ann['date'].dt.dayofyear\n",
    "X_ann['week_of_year'] = X_ann['date'].dt.isocalendar().week\n",
    "\n",
    "X_ann.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afff65a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ann = X_ann.drop(columns=['sales', 'date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34be6fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaler_ann = MinMaxScaler()\n",
    "\n",
    "X_ann_scaled = pd.DataFrame(X_scaler_ann.fit_transform(X_ann), columns=X_ann.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b39f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into training and testing sets\n",
    "X_train_ann, X_test_ann, y_train_ann, y_test_ann = train_test_split(X_ann_scaled, y_ann_scaled, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6512b562",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ANN model architecture\n",
    "ann_model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(X_train_ann.shape[1],)),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9298222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile ANN\n",
    "ann_model.compile(optimizer=Adam(), loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692b3fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "history = ann_model.fit(X_train_ann, y_train_ann, epochs=25, batch_size=32, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ccba240",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting on training set\n",
    "y_train_pred_ann = ann_model.predict(X_train_ann)\n",
    "\n",
    "# mse_ann_train = ann_model.evaluate(X_train_ann, y_train_ann)\n",
    "mse_ann_train = mean_squared_error(y_train_ann, y_train_pred_ann)\n",
    "\n",
    "print(\"Mean Squared Error on Training Set:\", mse_ann_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0efcab9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_ann_unscaled = y_scaler_ann.inverse_transform(y_train_pred_ann)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05445247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting on test set\n",
    "y_test_pred_ann = ann_model.predict(X_test_ann)\n",
    "\n",
    "# mse_ann_train = ann_model.evaluate(X_train_ann, y_train_ann)\n",
    "mse_ann_test = mean_squared_error(y_test_ann, y_test_pred_ann)\n",
    "\n",
    "print(\"Mean Squared Error on Test Set:\", mse_ann_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede6b934",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred_ann_unscaled = y_scaler_ann.inverse_transform(y_test_pred_ann)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c22071c",
   "metadata": {},
   "source": [
    "## Time Series Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8852ba",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef66c960",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_lstm = df_train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7112436a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract y\n",
    "y_lstm = X_lstm['sales']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42887307",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_lstm['day'] = X_lstm['date'].dt.day\n",
    "X_lstm['month'] = X_lstm['date'].dt.month\n",
    "X_lstm['dayofweek'] = X_lstm['date'].dt.dayofweek  # 0 = Monday\n",
    "X_lstm['week'] = X_lstm['date'].dt.isocalendar().week\n",
    "X_lstm['year'] = X_lstm['date'].dt.year\n",
    "\n",
    "X_lstm['date'] = X_lstm['date'].apply(lambda x: x.toordinal())\n",
    "\n",
    "X_lstm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1dcee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_lstm.drop(columns=['sales'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20990b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale and reshape y\n",
    "y_scaler_lstm = MinMaxScaler()\n",
    "\n",
    "y_lstm_scaled = y_scaler_lstm.fit_transform(y_lstm.values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655e3a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale and reshape X\n",
    "X_scaler_lstm = MinMaxScaler()\n",
    "\n",
    "X_lstm_scaled = X_scaler_lstm.fit_transform(X_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd326d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  function for creating sequences for LSTM \n",
    "\n",
    "def create_sequences(X, y, time_steps=7):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(time_steps, len(X)):\n",
    "        Xs.append(X[i - time_steps:i])\n",
    "        ys.append(y[i])\n",
    "    \n",
    "    Xs = np.array(Xs)\n",
    "\n",
    "    # If y is 2D (e.g., (n_samples, 1)), preserve its shape\n",
    "    ys = np.array(ys)\n",
    "    if len(ys.shape) == 1:\n",
    "        ys = ys.reshape(-1, 1)\n",
    "\n",
    "    return Xs, ys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed9ebf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating sequences for LSTM model\n",
    "X_lstm_seq, y_lstm_seq = create_sequences(X_lstm_scaled, y_lstm_scaled, time_steps=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd853bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting in test train set\n",
    "X_train_lstm, X_test_lstm, y_train_lstm, y_test_lstm = train_test_split(X_lstm_seq, y_lstm_seq, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412ab781",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model architecture\n",
    "lstm_model = Sequential([\n",
    "    LSTM(units=50, activation='relu', input_shape=(X_train_lstm.shape[1], X_train_lstm.shape[2])),\n",
    "    Dense(units=1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919c9072",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the LSTM model\n",
    "lstm_model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c0592b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "lstm_model.fit(X_train_lstm, y_train_lstm, epochs=25, batch_size=32, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537e0baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting on training set\n",
    "y_train_pred_lstm = lstm_model.predict(X_train_lstm)\n",
    "\n",
    "# mse_ann_train = ann_model.evaluate(X_train_ann, y_train_ann)\n",
    "mse_lstm_train = mean_squared_error(y_train_lstm, y_train_pred_lstm)\n",
    "\n",
    "print(\"Mean Squared Error on Training Set:\", mse_lstm_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a69a9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_lstm_unscaled = y_scaler_lstm.inverse_transform(y_train_pred_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5035f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting on testing set\n",
    "y_test_pred_lstm = lstm_model.predict(X_test_lstm)\n",
    "\n",
    "# mse_ann_train = ann_model.evaluate(X_train_ann, y_train_ann)\n",
    "mse_lstm_test = mean_squared_error(y_test_lstm, y_test_pred_lstm)\n",
    "\n",
    "print(\"Mean Squared Error on Test Set:\", mse_lstm_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5931732c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred_lstm_unscaled = y_scaler_lstm.inverse_transform(y_test_pred_lstm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c88376",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce1f360",
   "metadata": {},
   "source": [
    "########## Best practice:\n",
    "\n",
    "Split raw data into train/test.\n",
    "\n",
    "Fit the scaler only on the training set.\n",
    "\n",
    "Apply the scaler to both train and test.\n",
    "\n",
    "Then sequence both sets separately."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af608168",
   "metadata": {},
   "source": [
    "##### Data - X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50471e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cnn = df_train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c646f5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract y\n",
    "y_cnn = X_cnn['sales']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5740230f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cnn['day'] = X_cnn['date'].dt.day\n",
    "X_cnn['month'] = X_cnn['date'].dt.month\n",
    "X_cnn['dayofweek'] = X_cnn['date'].dt.dayofweek  # 0 = Monday\n",
    "X_cnn['week'] = X_cnn['date'].dt.isocalendar().week\n",
    "X_cnn['year'] = X_cnn['date'].dt.year\n",
    "\n",
    "X_cnn['date'] = X_cnn['date'].apply(lambda x: x.toordinal())\n",
    "\n",
    "X_cnn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e409129",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cnn.drop(columns=['sales'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace801bc",
   "metadata": {},
   "source": [
    "##### Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6902c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting in test train set\n",
    "X_train_cnn, X_test_cnn, y_train_cnn, y_test_cnn = train_test_split(X_cnn, y_cnn, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a87f35",
   "metadata": {},
   "source": [
    "##### Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f73e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaler for y\n",
    "y_scaler_cnn = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd07f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit Scaler on y train and reshape y train\n",
    "y_train_cnn_scaled = y_scaler_cnn.fit_transform(y_train_cnn.values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf6ef8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale and reshape y test\n",
    "y_test_cnn_scaled = y_scaler_cnn.transform(y_test_cnn.values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7312093b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaler for X\n",
    "X_scaler_cnn = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ea9248",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit Scaler on X train\n",
    "X_train_cnn_scaled = X_scaler_cnn.fit_transform(X_train_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e58bc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale X test \n",
    "X_test_cnn_scaled = X_scaler_cnn.transform(X_test_cnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3177213",
   "metadata": {},
   "source": [
    "##### Sequencing (reshaping) X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0452b80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cnn_scaled_seq, y_train_cnn_scaled_seq = create_sequences(X_train_cnn_scaled, y_train_cnn_scaled, time_steps=7)\n",
    "X_test_cnn_scaled_seq, y_test_cnn_scaled_seq = create_sequences(X_test_cnn_scaled, y_test_cnn_scaled, time_steps=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abdfc901",
   "metadata": {},
   "source": [
    "##### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68695cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model = Sequential([\n",
    "    Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(X_train_cnn_scaled_seq.shape[1], X_train_cnn_scaled_seq.shape[2])),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dac2103",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5b989b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model.fit(X_train_cnn_scaled_seq, y_train_cnn_scaled_seq, epochs=25, batch_size=32, validation_split=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23047be",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_cnn_test = cnn_model.evaluate(X_test_cnn_scaled_seq, y_test_cnn_scaled_seq)\n",
    "\n",
    "print(f\"Test Loss: {loss_cnn_test}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5af5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting on training set\n",
    "y_test_pred_cnn = lstm_model.predict(X_test_cnn_scaled_seq)\n",
    "\n",
    "# mse_ann_train = ann_model.evaluate(X_train_ann, y_train_ann)\n",
    "mse_cnn_test = cnn_model.evaluate(X_test_cnn_scaled_seq, y_test_cnn_scaled_seq)\n",
    "\n",
    "print(\"Mean Squared Error on Training Set:\", mse_cnn_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003c6200",
   "metadata": {},
   "source": [
    "### BI-LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c656e1",
   "metadata": {},
   "source": [
    "We are going to use same components that we created for LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c000890f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bilstm_model = Sequential([\n",
    "    Bidirectional(LSTM(units=50, activation='relu'), input_shape=(X_train_lstm.shape[1], X_train_lstm.shape[2])),\n",
    "    Dense(units=1)\n",
    "])\n",
    "bilstm_model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f616bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the LSTM model\n",
    "bilstm_model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1253b215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "bilstm_model.fit(X_train_lstm, y_train_lstm, epochs=25, batch_size=32, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4037de3e",
   "metadata": {},
   "source": [
    "### ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "30410a64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['date', 'store', 'item', 'sales'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "X_arima = df_train.copy()\n",
    "\n",
    "print(X_arima.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c8f401",
   "metadata": {},
   "source": [
    "Check the skew and see if the data requires adjustment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "600db482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-skew: 0.867\n",
      "Pre-kurt: 0.509\n"
     ]
    }
   ],
   "source": [
    "pre_skew = X_arima['sales'].skew()\n",
    "pre_kurt = X_arima['sales'].kurt()\n",
    "\n",
    "print(f'Pre-skew: {pre_skew:.3f}')\n",
    "print(f'Pre-kurt: {pre_kurt:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb66ae6",
   "metadata": {},
   "source": [
    "Pre-skew = 0.867: This indicates a moderate right (positive) skew, meaning the distribution has a longer tail on the right side - Apply transformation\n",
    "\n",
    "Pre-kurt = 0.509 < 3: Not many outliers - doesn't need any special handling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f10df198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['date', 'store', 'item', 'sales'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#log transformation\n",
    "X_arima['sales'] = np.log1p(X_arima['sales'])\n",
    "\n",
    "print(X_arima.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ad6b5bb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post-skew: -0.376\n",
      "Post-kurt: -0.239\n"
     ]
    }
   ],
   "source": [
    "post_skew = X_arima['sales'].skew()\n",
    "post_kurt = X_arima['sales'].kurt()\n",
    "\n",
    "print(f'Post-skew: {post_skew:.3f}')\n",
    "print(f'Post-kurt: {post_kurt:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dca2e6b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['date', 'store', 'item', 'sales'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "y = X_arima['sales']\n",
    "\n",
    "print(X_arima.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cf10d936",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_stationarity_for_all(df, freq='D'):\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    \n",
    "    # Set 'date' as the index\n",
    "    df.set_index('date', inplace=True)\n",
    "    \n",
    "    # Initialize a list to store results\n",
    "    results = []\n",
    "    \n",
    "    # Iterate over all unique store-item combinations\n",
    "    for (store, item), group in df.groupby(['store', 'item']):\n",
    "        # Resample sales by the specified frequency (sum or mean depending on your data)\n",
    "        resampled_sales = group.resample(freq).sum()\n",
    "\n",
    "        # Apply the ADF test to the resampled sales data\n",
    "        result = adfuller(resampled_sales['sales'])\n",
    "\n",
    "        # Store the results\n",
    "        results.append({\n",
    "            'store': store,\n",
    "            'item': item,\n",
    "            'ADF Test Statistic': result[0],\n",
    "            'p-value': result[1],\n",
    "            'Critical Value (1%)': result[4]['1%'],\n",
    "            'Critical Value (5%)': result[4]['5%'],\n",
    "            'Critical Value (10%)': result[4]['10%'],\n",
    "            'Stationary': 'Yes' if result[1] < 0.05 else 'No'\n",
    "        })\n",
    "    \n",
    "    # Convert results into a DataFrame\n",
    "    results_df = pd.DataFrame(results)\n",
    "    return results_df\n",
    "\n",
    "result_stat_arima = test_stationarity_for_all(X_arima)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1aba91e",
   "metadata": {},
   "source": [
    "Most combo are stationary so we will consider overall its stationary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "88c60bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_arima_fixed_order(series, arima_order):\n",
    "    \"\"\"Evaluate a single ARIMA order on a time series and return MSE.\"\"\"\n",
    "    if len(series) < 30:\n",
    "        return None  # Skip short series\n",
    "\n",
    "    train_size = int(len(series) * 0.8)\n",
    "    train, test = series[:train_size], series[train_size:]\n",
    "    history = list(train)\n",
    "    predictions = []\n",
    "\n",
    "    try:\n",
    "        for t in range(len(test)):\n",
    "            model = ARIMA(history, order=arima_order)\n",
    "            with warnings.catch_warnings():\n",
    "                warnings.simplefilter(\"ignore\")\n",
    "                model_fit = model.fit()\n",
    "            yhat = model_fit.forecast(steps=1)[0]\n",
    "            predictions.append(yhat)\n",
    "            history.append(test[t])\n",
    "        error = mean_squared_error(test, predictions)\n",
    "        return error\n",
    "    except:\n",
    "        return None  # Skip if model fails\n",
    "    \n",
    "\n",
    "def evaluate_all_combos_fixed_order(df, arima_order):\n",
    "    \"\"\"Evaluate fixed ARIMA order across all (store, item) combinations.\"\"\"\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df.sort_values('date', inplace=True)\n",
    "    \n",
    "    results = []\n",
    "    grouped = df.groupby(['store', 'item'])\n",
    "\n",
    "    for (store, item), group in grouped:\n",
    "        ts = group.groupby('date')['sales'].sum().sort_index()\n",
    "        mse = evaluate_arima_fixed_order(ts.values, arima_order)\n",
    "        if mse is not None:\n",
    "            results.append({'store': store, 'item': item, 'mse': mse})\n",
    "        else:\n",
    "            print(f\"Skipped {store}-{item} (insufficient data or model failure)\")\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b9828c8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['date', 'store', 'item', 'sales'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "X_arima = df_train.copy()\n",
    "\n",
    "X_arima['sales'] = np.log1p(X_arima['sales'])\n",
    "\n",
    "print(X_arima.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17cc334a",
   "metadata": {},
   "outputs": [],
   "source": [
    "arima_results_711 = evaluate_all_combos_fixed_order(X_arima, (7,1,1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
